# *Xylella fastidiosa* (Xf) annotation, orthology search and phylogeny inference
(created 09/2020)  
Pipeline to create a phylogeny of the core genome of 102 publicly available Xf genomes from GenBank. https://github.com/harrisonlab/Frankia used as guideline.

## Get sequences.

### 1. Download Xf genomic sequences from GenBank.
The FTP links to the currently 102 publicly available Xf genomes on GenBank (dated 09/2020) are saved in [20200910_xf102_genbank_urls_fna.txt]. Use the following bash script to download all sequences in the file to your genome directory:
```bash
for line in $(cat 20200910_xf102_genbank_urls_gbff.txt); do
  wget $line /data/data2/scratch2/mirabl/Xf_proj/SEQ/20200910_xf102/GBFF/
done
```

### 2. Unzip all downloaded sequences.
```bash
gunzip GC*
```
or
```bash
gzip -d GC*
```

### 3. Change FASTA file names to their strain names.
```bash
cd /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/

for file in /data/data2/scratch2/mirabl/Xf_proj/SEQ/20200910_xf102/FNA/*.fna; do
  file_short=$(basename $file | sed s/".fna"//g)
  echo $file_short
  cp "$file" "$file_short".fna
done

for file in ./*.fna; do
  cp "$file" "$(echo "$file" | cut -d_ -f1,2)"
done

for file in ./*; do
  file_short=$(basename $file | grep "$(sed s/"GCA_"//g)" /data/data2/scratch2/mirabl/Xf_proj/SEQ/xf102_strains.csv | cut -d, -f2)
  echo $file_short
  cp "$file" "$file_short".fasta
done  
```

### 4. Download annotation files (.gbff) from GenBank.
Repeat steps 1 and 2 for this, but instead using the [20200910_xf102_genbank_urls_gbff.txt] file, which contains FTP links to the annotation files.  
The following represenative genomes (FASTA and annotation files also obtained from GenBank) were used as outgroups:  
*Xanthomonas campestris* pv. *campestris* str. ATCC 33913
```bash
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/007/145/GCF_000007145.1_ASM714v1/GCF_000007145.1_ASM714v1_genomic.fna.gz /data/data2/scratch2/mirabl/Xf_proj/SEQ/20200910_xf102/FNA/
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/007/145/GCF_000007145.1_ASM714v1/GCF_000007145.1_ASM714v1_genomic.gbff.gz /data/data2/scratch2/mirabl/Xf_proj/SEQ/20200910_xf102/GBFF/
```

*Xanthomonas oryzae* pv. *oryzae* PXO99A
```bash
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/019/585/GCF_000019585.2_ASM1958v2/GCF_000019585.2_ASM1958v2_genomic.fna.gz /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/019/585/GCF_000019585.2_ASM1958v2/GCF_000019585.2_ASM1958v2_genomic.gbff.gz /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009
```

*Xylella taiwanensis* strain PLS229 (Wufong-1)
```bash
wget https://ftp.ncbi.nlm.nih.gov/genomes/genbank/bacteria/Xylella_taiwanensis/latest_assembly_versions/GCA_000576405.1_Wufong-1/GCA_000576405.1_Wufong-1_cds_from_genomic.fna.gz /data/data2/scratch2/mirabl/Xf_proj/SEQ/20200910_xf102/FNA/
wget https://ftp.ncbi.nlm.nih.gov/genomes/genbank/bacteria/Xylella_taiwanensis/latest_assembly_versions/GCA_000576405.1_Wufong-1/GCA_000576405.1_Wufong-1_genomic.gbff.gz /data/data2/scratch2/mirabl/Xf_proj/SEQ/20200910_xf102/FNA/
```

### 5. Change the annotation file names to their strain names and replace the .gbff extension with .gbk.
```bash
cd /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/

for file in /data/data2/scratch2/mirabl/Xf_proj/SEQ/20200910_xf102/GBFF/*.gbff ; do
  file_short=$(basename $file | sed s/".gbff"//g)
  echo $file_short
  cp "$file" "$file_short".gbff
done

for file in ./GCA_*; do
  file_short=$(basename $file | grep "$(sed s/"GCA_"//g)" /data/data2/scratch2/mirabl/Xf_proj/SEQ/xf102_strains.csv | cut -d, -f2)
  echo $file_short
  cp "$file" "$file_short".gbk
done  
```

# Annotation and filtering.

### 6. Create a Genus database using Prokka. First, open a screen session, log into a node and run the code below in Bioconda base environment.
```bash
cd /home/mirabl/
prokka-genbank_to_fasta_db /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/GBK/*.gbk > /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/xf.faa
cd-hit -i /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/xf.faa -o xf -T 0 -M 0 -g 1 -s 0.8 -c 0.9
mv xf* /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/
rm -fv /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/xf.faa /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/xf.bak.clstr /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/xf.clstr
makeblastdb -dbtype prot -in /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/xf
mkdir /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/DB_prokka
mv /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/xf.* /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/DB_prokka/
```

### 7. Run Prokka and compress (gzip) files.
See https://github.com/tseemann/prokka for documentation.
```bash
cd /home/mirabl/
for file in /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/*.fasta; do
  file_short=$(basename $file | sed s/".fasta"//g)
  echo $file_short
  prokka --usegenus --genus /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/xf $file --outdir /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/$file_short
done
gzip -f /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/*.fasta
mkdir /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/FASTA
mv /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/*.fasta.gz /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/FASTA
```

Move all annotated SUBDIRECTORIES to a new directory named 'Annotation'
```bash
mkdir /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Annotation/
mv /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/* /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Annotation/
```

### 8. Filter genomes based on Levy et al (2018) GWAS paper.
Run quast.py on all FASTA files
```bash
cd /home/mirabl/
quast.py /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/FASTA/*.fasta.gz
mv /home/mirabl/quast_results /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/
```

Filter genomes based on N50 >=40kbp and save only unique genomes into a new file:
```bash
cd /home/mirabl/
python /projects/oldhome/hulinm/git_repos/tools/analysis/python_effector_scripts/extract_N50filtered_genomes.py /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/quast_results/results_2020_10_07_14_41_08/transposed_report.tsv > /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/report2.txt
cut -f1 -d " " /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/report2.txt | uniq > /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/report3.txt
```

Save reported genomes in a new directory named 'Filtered':
```bash
mkdir /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered
cd /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/
for file in $(cat report3.txt); do
  cp  /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/FASTA/*.fasta.gz Filtered/
done
```

### 9. Run CheckM on filtered genomes from step 8. CheckM screens for contaminationa nd removes genomes with a contamination level >5%. Run this in a screen / tmux session.
First, open screen session. Then log into a a node and run the following script:
```bash
gunzip /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/*.fasta.gz
mkdir /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/Checkm
for file in /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/*.fasta ; do
  file_short=$(basename $file | sed s/".fasta"//g)
  echo $file_short
  mkdir -p /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/Checkm/"$file_short"/Checkm
  cp $file /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/Checkm/"$file_short"
  Jobs=$(squeue | grep -i 'checkm' | wc -l)
    while [ $Jobs -gt 5 ]; do
      sleep 10
      printf "."
      Jobs=$(squeue | grep -i 'checkm' | wc -l)
    done
  sbatch /home/mirabl/SUB_SLURM/checkm_sub.sh /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/Checkm/"$file_short" /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/Checkm/"$file_short"/Checkm
done
```
Run CheckM report:
```bash
cd /home/mirabl
for file in /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/*.fasta; do
  file_short=$(basename $file | sed s/".fasta"//g)
  checkm qa /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/Checkm/"$file_short"/Checkm/lineage.ms /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/Checkm/"$file_short"/Checkm > /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/Checkm/"$file_short"/Checkm/report
done
```

Append CheckM report for each genome into a single summary file "checkm_report"
```bash
cd /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/Checkm/
head -11 11399/Checkm/report | tail -5 > checkm_report
for file in ./*; do
  file_short=$(basename $file)
  echo $file_short
  cat "$file_short"/Checkm/report | head -11 | tail -2 >> checkm_report
done
```

## Orthology search.

### 10. Perform orthology analysis on filtered, clean genomes using OrthoFinder.
Rename .faa files (from PROKKA output) to contain genome name not PROKKA output:
```bash
for file in /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/FASTA/*.fasta.gz; do
  file_short=$(basename $file | sed s/".fasta.gz"//g)
  echo $file_short
  cp /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Annotation/"$file_short"/*.faa /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Annotation/"$file_short"/"$file_short".faa
done
```

### 11. Copy all .faa files to a new directory named 'Analysis'.
```bash
mkdir /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Analysis
cp /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Annotation/*/*.faa /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Analysis
```

### 12. Modify all fasta files to remove description, which is the correct format for OrthoMCL.
Each fasta header must be in format of strain|peg.number
```bash
for file in /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Analysis/*.faa; do
  file_short=$(basename $file | sed s/".faa"//g)
  echo $file_short
  sed 's/ .*//' $file | sed s/"_"/"|peg."/g > /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Analysis/"$file_short".fa
done
```

```bash
for file in /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Analysis/*.fa; do
  id=$(less $file | grep ">" | cut -f1 -d "|" | sed s/">"//g | uniq)
  file_short=$(basename $file | sed s/".fa"//g)
  echo $id
  echo $file_short
  sed s/"$id"/"$file_short"/g $file > /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Analysis/$file_short.fasta
done
```

### 13. Remove manually those that did not pass CheckM and also those that did not pass N50 limit and move to new directory OrthoFinder/Formatted
CheckM report: ```/data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/Checkm/checkm_report```
N50 report: ```/data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/report3.txt```
```bash
mkdir /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/ /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted
for file in /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Filtered/*.fasta; do
  file_short=$(basename $file | sed s/".fasta"//g)
  echo $file_short
  mv /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/Analysis/$file_short.fasta /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/$file_short.fasta
done
```

### 14. Run OrthoFinder.
Submit to HPC (change input directory within job submission script).
```bash
sbatch /home/mirabl/SUB_SLURM/Xf_proj/orthofinder.sh
```

### 15. Concatenate all protein FASTA files (output from step 14.).
```bash
cat /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/*.fasta > /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/proteins.fasta
```

### 16. Extract FASTA sequences for each orthogroup.
```bash
cd /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/
sed s/"OG"/"orthogroup"/g Orthogroups.txt > Orthogroups2.txt
sed s/"OG"/"orthogroup"/g Orthogroups_SingleCopyOrthologues.txt > Orthogroups_SingleCopyOrthologues2.txt
mkdir Fasta/
python /projects/oldhome/hulinm/git_repos/tools/pathogen/orthology/orthoMCL/orthoMCLgroups2fasta.py --orthogroups Orthogroups2.txt --fasta /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/proteins.fasta --out_dir Fasta/
mkdir Fasta/Single_copy
for file in $(cat Orthogroups_SingleCopyOrthologues2.txt); do
  echo $file
  cp Fasta/"$file".fa Fasta/Single_copy
done
```

## Alignment.

### 17. Align the protein sequences of each orthogroup. Submits each orthogroup to HPC.
```bash
for file in /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/*.fa; do
  file_short=$(basename $file | sed s/".fa"//g)
  Jobs=$(squeue | grep 'clustalo' | wc -l)
    while [ $Jobs -gt 100 ]; do
      sleep 10
      printf "."
      Jobs=$(squeue | grep 'clustalo' | wc -l)
    done
  sbatch /home/mirabl/SUB_SLURM/clustalo_sub.sh $file
done
```

### 18. Correct alignments using GBlocks.
First, log into HPC node and then open a conda environment.
```bash
cd /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/
rm -f slurm-*
cd ~
for file in /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/*.aln; do
  Gblocks $file -t=p -d=y
  echo $file
done
```

### 19. Rename sequences to make them shorter and compatible (change from QTJS01000001.1|peg.00473 to genome name only, i.e. QTJS01000001.1). This script also renames the file_name by removing the .fa.aln-gb extension.
```bash
cd /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/
mkdir Fasta/Single_copy/Align
for fasta in Fasta/Single_copy/*.fa.aln-gb; do
  name=$(basename $fasta | sed s/".fa.aln-gb"//g)
  sed '/^>/ s/|.*//' $fasta > Fasta/Single_copy/Align/"$name"
done
```

### 20. Convert from FASTA to nexus format.
```bash
cd ~
for file in $(cat /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Orthogroups_SingleCopyOrthologues2.txt); do
  echo $file
  perl /projects/oldhome/hulinm/git_repos/tools/analysis/python_effector_scripts/alignment_convert.pl -i /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/"$file" -o /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/"$file".nex -f nexus -g fasta
done
```

### 21. Concatenate single copy orthogroup alignments. Change the path to the input files within the python script.
Some bug prevents the Python script from using an input from ```/data/data2/scratch2/```, therefore I first copied all orthogroup Nexus files to ```~```and then ran the code.
```bash
cd /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/
python /home/mirabl/local/Scripts/concatenate.py
cp combined.nex /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/
```
Use nano to change datatype to ```protein``` within the ```combined.nex``` output file.

## Create phylogeny.

### 22. Convert from nexus to phylip format.
First open a screen session and then log into an HPC node.
```bash
cd /home/mirabl/
perl /projects/oldhome/hulinm/git_repos/tools/analysis/python_effector_scripts/alignment_convert.pl -i /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/combined.nex -o /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/combined.phy -f phylip -g nexus
```

### 23. Make partition model file.
```bash
cd /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/
grep charset combined.nex | sed s/charset//g | sed s/".nex"//g | sed s/"-gb"//g | sed s/" o"/"o"/g | sed s/";"//g > positions
```

### 24. Order list of genes.
```bash
cd /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/
cut -f1 -d " " positions > list
```

### 25. Run the protein model tester on individual alignments.
First open a screen session, log into an HPC node and open a conda environment.
```bash
cd /home/mirabl/
for file in $(cat /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Orthogroups_SingleCopyOrthologues2.txt); do
  echo $file
  perl /projects/oldhome/hulinm/git_repos/tools/analysis/python_effector_scripts/alignment_convert.pl -i /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/"$file" -o /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/"$file".phy -f phylip -g fasta
done
```

### 26. Test protein models for each orthogroup.
```bash
cd /home/mirabl/
for file in /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/*.phy; do
  file_short=$(basename $file | sed s/".phy"//g )
  echo $file_short Jobs=$(squeue | grep 'prottest' | wc -l);
    while [ $Jobs -gt 50 ]; do
      sleep 10;
      printf ".";
      Jobs=$(squeue | grep 'prottest' | wc -l)
    done
  sbatch /home/mirabl/SUB_SLURM/prottest_sub.sh "$file" /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/"$file_short"_model
done
```

### 27. Get best model name into its own file.
```bash
mkdir /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/Model2/
for file in /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/*_model; do
  file_short=$(basename $file | sed s/"_model"//g)
  grep -i "Best model according to LnL" $file | cut -d " " -f6 > /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/Model2/"$file_short"
done
```

### 28. Move model files.
```bash
mkdir /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/Prottest_model2
for file in /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/*_model; do
  file_short=$(basename $file | sed s/"_model"//g)
  cp $file /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/Prottest_model2/"$file_short"
done
```

### 29. Proteins.
```bash
for file in $(cat /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/list); do
  cat /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/Model2/"$file" >> /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/Model2/models
done
```

### 30. Add sequence evolution model.
Make the final partition file.
```
cd /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups
mkfifo pipe1
mkfifo pipe2
cut -f1 Fasta/Single_copy/Align/Model2/models > pipe1 &
cut -f1,2,3 Fasta/Single_copy/Align/positions > pipe2 &
paste pipe1 pipe2 > Fasta/Single_copy/Align/partition
mv pipe* /data2/scratch2/mirabl/Discard
sed s/"\t"/", "/g Fasta/Single_copy/Align/partition > Fasta/Single_copy/Align/partition_file
```

### 31. Run RAxML on concatenated protein alignment. Change file names within SLURM submission file.
```
cd /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/Model2
sbatch /home/mirabl/SUB_SLURM/raxml_partition_sub.sh
```

### 32. Run IQTREE.
```
sbatch /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/combined.phy /data/data2/scratch2/mirabl/Xf_proj/NCBI_Xf102/Analysis_202009/OrthoFinder/Formatted/OrthoFinder/Results_Oct13_4/Orthogroups/Fasta/Single_copy/Align/partition_file2
```
